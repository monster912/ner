{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRL Task\n",
    "의미역 인식(Semantic Role Labeling, SRL)은 자연어 텍스트에서 하나의 동사(predicate)가 어떤 argument를 가지고 있는지 찾아내는 작업입니다.\n",
    "\n",
    "개체명 인식과 비슷하게 각각의 argument에 대한 span을 BIO로 태깅하고, argument type을 맞춰야 합니다. 또한, 한 문장 안에 있는 predicate가 여러 개일 경우, 각각의 predicate에 대해 서로 다른 argument들을 찾아내어야 합니다.\n",
    "\n",
    "<img src=\"files/srl1.PNG\">\n",
    "\n",
    "이 task 역시 개체명 인식에서 했던 것처럼 Word embedding 기반의 Bi-directional LSTM을 사용하여 구현해 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from seqeval.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "import torch.nn.utils.rnn as rnn\n",
    "from data import parse_srl, one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### device information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SRL model\n",
    "개체명 인식 모듈과 동일하게, Word embedding을 사용하고 LSTM을 통과시키는 모델을 만들어 보겠습니다. 하지만 이번에는 각 문장에서 predicate의 위치를 1로 표시하는 one-hot vector를 추가하여, predicate에 따라 argument를 다르게 예측할 수 있게 만들었습니다.(`forward`함수의 `predicate_input`인자)\n",
    "<img src=\"files/srl2.PNG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRLModel(nn.Module):\n",
    "    def __init__(self, we, hidden_size, tag_size):\n",
    "        super(SRLModel, self).__init__()\n",
    "        self.we = nn.Embedding.from_pretrained(torch.FloatTensor(we))\n",
    "        self.lstm = nn.LSTM(input_size=self.we.embedding_dim+1, hidden_size=hidden_size, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.ffnn = nn.Linear(hidden_size * 2, tag_size)\n",
    "    \n",
    "    def forward(self, word_input, predicate_input, word_lens, labels=None):\n",
    "        we = self.we(word_input)\n",
    "        predicate_input = torch.unsqueeze(predicate_input, 2)\n",
    "        lstm_input = torch.cat((we, predicate_input), dim=-1)\n",
    "        lstm_input = rnn.pack_padded_sequence(lstm_input, word_lens, batch_first=True, enforce_sorted=False)\n",
    "        out, _ = self.lstm(lstm_input)\n",
    "        out, output_lens = rnn.pad_packed_sequence(out, batch_first=True)\n",
    "        out = F.dropout(out)\n",
    "        pred = self.ffnn(out)\n",
    "        \n",
    "        if labels is not None:\n",
    "            pb = torch.zeros(torch.sum(output_lens), pred.size()[-1])\n",
    "            lb = torch.zeros(torch.sum(output_lens), dtype=torch.long)\n",
    "            lsum = 0\n",
    "            for p, la, le in zip(pred, labels, output_lens):\n",
    "                pb[lsum:lsum+le] = p[:le, :]\n",
    "                lb[lsum:lsum+le] = la[:le]\n",
    "                lsum += le\n",
    "            pred = pb\n",
    "            labels = lb\n",
    "            \n",
    "            loss = F.cross_entropy(pred, labels)\n",
    "            return loss\n",
    "        else:\n",
    "            pred = F.softmax(pred, dim=-1)\n",
    "            pred = torch.argmax(pred, dim=-1)\n",
    "            return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Generation\n",
    "NER과 같은 구조체를 사용하여 dataset을 만들어 봅니다. NER과 다른 점은, 하나의 문장에 여러 predicate가 있을 수 있다는 점과, label이 predicate마다 하나씩 있다는 것입니다. 결론적으로, 하나의 문장에 있는 token마다 여러 개의 label을 가질 수 있다는 것입니다. \n",
    "\n",
    "또한, predicate의 위치를 나타내는 정보가 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRLDataElement:\n",
    "    def __init__(self, tokens, predicates, args):\n",
    "        # tokens: list of str\n",
    "        # predicates: list of int: location of predicates\n",
    "        # args: list of (list of str): argument tag of tokens, each related to predicate\n",
    "        assert len(predicates) == len(args)\n",
    "        self.tokens = tokens\n",
    "        self.predicates = predicates\n",
    "        self.args = args\n",
    "    def __len__(self):\n",
    "        return len(self.predicates)\n",
    "    def __getitem__(self, index):\n",
    "        assert type(index) is int\n",
    "        return self.tokens, self.args[index], self.predicates[index]\n",
    "    def token_len(self):\n",
    "        return len(self.tokens)\n",
    "    def __iter__(self):\n",
    "        for i in range(len(self)):\n",
    "            yield self[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRLDataset(Dataset):\n",
    "    def __init__(self, tokens, predicates, labels, token_index_dict, tag_index_dict):\n",
    "        self.data = []\n",
    "        error_count = 0\n",
    "        for t, p, l in zip(tokens, predicates, labels):\n",
    "            try:\n",
    "                self.data.append(SRLDataElement(t, p, [*zip(*l)]))\n",
    "            except:\n",
    "                error_count += 1\n",
    "        print(\"Errors: %d\" % error_count)\n",
    "        self.token2i = token_index_dict\n",
    "        self.tag2i = tag_index_dict\n",
    "        self.maxlen = max(map(SRLDataElement.token_len, self.data))\n",
    "        self.ld = {}\n",
    "        self.lbuf = 0\n",
    "        print(self.maxlen)\n",
    "        for d in self.data:\n",
    "            self.ld[self.lbuf] = d\n",
    "            self.lbuf += len(d)\n",
    "    def __len__(self):\n",
    "        return self.lbuf\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        target = self.data[0]\n",
    "        imod = 0\n",
    "        for i, d in self.ld.items():\n",
    "            if i > index: break\n",
    "            target = d\n",
    "            imod = i\n",
    "        index -= imod\n",
    "        token, arg, pred_loc = target[index]\n",
    "        l = len(token)\n",
    "        return torch.tensor([self.token2i[x] if x in self.token2i else 0 for x in token] + ([0] * (self.maxlen - l))), \\\n",
    "               torch.tensor([self.tag2i[x] for x in arg] + ([0] * (self.maxlen - l))), \\\n",
    "               torch.tensor(one_hot(pred_loc, self.maxlen)).to(dtype=torch.float32), \\\n",
    "               l\n",
    "    def __iter__(self):\n",
    "        for d in self.data:\n",
    "            for x in d:\n",
    "                yield x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load corpus\n",
    "NER과 같은 방식으로 데이터를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_ids = {\"UNK_\": 0}\n",
    "with open(\"wiki_tok_glove_300.word\", encoding=\"UTF8\") as f:\n",
    "    for line in f.readlines():\n",
    "        tok_ids[line.strip()] = len(tok_ids)\n",
    "we = np.load(\"wiki_tok_glove_300.npy\")\n",
    "we = np.vstack([np.zeros([1, we.shape[1]]), we])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors: 1\n",
      "55\n",
      "Errors: 0\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "tt, tp, tl = parse_srl(\"corpus/srl_train.conll\")\n",
    "dt, dp, dl = parse_srl(\"corpus/srl_test.conll\")\n",
    "lset = set([])\n",
    "for l in tl+dl:\n",
    "    for ll in l:\n",
    "        for label in ll:\n",
    "            lset.add(label)\n",
    "ldict = {}\n",
    "for i, l in enumerate(lset):\n",
    "    ldict[l] = i\n",
    "i2tag = {v: k for k, v in ldict.items()}\n",
    "train_dataset = SRLDataset(tt, tp, tl, tok_ids, ldict)\n",
    "test_dataset = SRLDataset(dt, dp, dl, tok_ids, ldict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "위에서 만든 SRL 모듈의 instance를 만들고, 이를 optimizer에 등록한 뒤, NER과 같은 방식으로 train합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_module = SRLModel(we, 256, len(ldict)).to(device)\n",
    "optimizer = torch.optim.Adam(srl_module.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss 233.364365:   0%|          | 5/1000 [01:54<6:35:52, 23.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 F1 score 31.06\n",
      "Best F1 31.06 at Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Loss 202.115875:   1%|          | 10/1000 [03:50<6:45:07, 24.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 F1 score 36.77\n",
      "Best F1 36.77 at Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 Loss 193.700775:   2%|▏         | 15/1000 [05:47<6:42:01, 24.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 F1 score 38.29\n",
      "Best F1 38.29 at Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 Loss 188.891785:   2%|▏         | 20/1000 [07:40<6:29:08, 23.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 F1 score 38.27\n",
      "Best F1 38.29 at Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 Loss 185.332901:   2%|▎         | 25/1000 [09:35<6:36:41, 24.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 F1 score 39.06\n",
      "Best F1 39.06 at Epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 Loss 181.773911:   3%|▎         | 30/1000 [11:31<6:35:23, 24.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 F1 score 39.24\n",
      "Best F1 39.24 at Epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35 Loss 178.960861:   4%|▎         | 35/1000 [13:27<6:32:40, 24.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 F1 score 39.46\n",
      "Best F1 39.46 at Epoch 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40 Loss 175.176315:   4%|▍         | 40/1000 [15:23<6:32:34, 24.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 F1 score 39.67\n",
      "Best F1 39.67 at Epoch 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45 Loss 171.276398:   4%|▍         | 45/1000 [17:14<6:10:55, 23.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 F1 score 39.67\n",
      "Best F1 39.67 at Epoch 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50 Loss 167.066177:   5%|▌         | 50/1000 [19:10<6:23:53, 24.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 F1 score 40.16\n",
      "Best F1 40.16 at Epoch 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55 Loss 162.825195:   6%|▌         | 55/1000 [21:02<6:07:04, 23.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 F1 score 39.92\n",
      "Best F1 40.16 at Epoch 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60 Loss 158.694855:   6%|▌         | 60/1000 [22:56<6:11:29, 23.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 F1 score 39.53\n",
      "Best F1 40.16 at Epoch 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65 Loss 154.436813:   6%|▋         | 65/1000 [24:49<6:07:40, 23.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 F1 score 39.80\n",
      "Best F1 40.16 at Epoch 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70 Loss 149.765671:   7%|▋         | 70/1000 [26:43<6:07:56, 23.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 F1 score 39.32\n",
      "Best F1 40.16 at Epoch 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75 Loss 144.760468:   8%|▊         | 75/1000 [28:35<5:58:33, 23.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 F1 score 39.03\n",
      "Best F1 40.16 at Epoch 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79 Loss 141.496765:   8%|▊         | 79/1000 [29:59<5:32:02, 21.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 F1 score 38.83\n",
      "Best F1 40.16 at Epoch 50\n",
      "No better result since epoch 50 - stop training\n"
     ]
    }
   ],
   "source": [
    "max_epoch = 1000\n",
    "eval_per_epoch = 5\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=32)\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=32)\n",
    "\n",
    "best_f1 = 0\n",
    "best_epoch = 0\n",
    "nbc = 0\n",
    "# ner_parallel = nn.DataParallel(ner_module)\n",
    "tq = tqdm(range(1, max_epoch+1))\n",
    "for epoch in tq:\n",
    "    srl_module.train()\n",
    "    total_loss = 0\n",
    "    for train_elem in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        token_batch, tag_batch, pred_batch, data_len = [tensor.to(device) for tensor in train_elem]\n",
    "        max_data_len = torch.max(data_len)\n",
    "        loss = srl_module(token_batch, pred_batch, data_len, tag_batch)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    tq.desc = \"Epoch %d Loss %f\" % (epoch, total_loss)\n",
    "    if epoch % eval_per_epoch == 0:\n",
    "        srl_module.eval()\n",
    "        preds = []\n",
    "        golds = []\n",
    "        lens_with_pad = []\n",
    "        data_lens = []\n",
    "        for token_batch, tag_batch, pred_batch, data_len in test_dataloader:\n",
    "            \n",
    "            token_batch, pred_batch, data_len = token_batch.to(device), pred_batch.to(device), data_len.to(device)\n",
    "            pred = srl_module(token_batch, pred_batch, data_len)\n",
    "            for p, t, d in zip(pred, tag_batch, data_len):\n",
    "                preds.append([i2tag[x.item()] for x in p[:d]])\n",
    "                golds.append([i2tag[x.item()] for x in t[:d]])\n",
    "                data_lens.append(d)\n",
    "        f1 = f1_score(golds, preds)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_epoch = epoch\n",
    "            torch.save(srl_module.state_dict(), \"srl_model\")\n",
    "        \n",
    "        idx = 0\n",
    "        with open(\"srl_debug/eval_%d.tsv\" % epoch, \"w\", encoding=\"UTF8\") as f:\n",
    "            for token, tag, predicate_loc in test_dataset:\n",
    "                predicate_loc = one_hot(predicate_loc, len(token))\n",
    "                for i, (tok, t, predloc) in enumerate(zip(token, tag, predicate_loc)):\n",
    "                    assert golds[idx][i] == t\n",
    "                    f.write(\"\\t\".join([tok, str(predloc), t, preds[idx][i]])+\"\\n\")\n",
    "                f.write(\"\\n\")\n",
    "                idx += 1\n",
    "        print(\"Epoch %d F1 score %.2f\" % (epoch, f1 * 100))\n",
    "        print(\"Best F1 %.2f at Epoch %d\" % (best_f1 * 100, best_epoch))\n",
    "        if epoch - best_epoch >= 30:\n",
    "            print(\"No better result since epoch %d - stop training\" % best_epoch)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
