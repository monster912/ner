{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER Task\n",
    "개체명 인식(Named Entity Recognition, NER)은 자연어 텍스트에서 사람, 기관, 지명 등의 단어열을 뽑아내는 task입니다.\n",
    "\n",
    "<img src=\"files/ner1.PNG\">\n",
    "\n",
    "텍스트를 형태소 단위로 분해한 뒤, 개체의 범위를 Begin, Inside, Outside를 나타내는 BIO 태깅을 통해 표현합니다. \n",
    "\n",
    "BIO 태그와 함께 개체의 타입을 맞추는 것이 개체명 인식의 최종 목적입니다. 태그에 대한 예시는 [예시 파일](corpus/parsed.txt)을 참고해 주세요.\n",
    "<img src=\"files/ner2.PNG\">\n",
    "\n",
    "\n",
    "이 task에서는 Word index 기반과 Word embedding 기반으로 간단한 Bi-directional LSTM을 사용하여 개체명 인식 모듈을 만들어 보겠습니다.\n",
    "\n",
    "모듈은 pytorch 기반으로, pytorch 모듈은 [이 노트북](cifar10_tutorial.ipynb)를 참고해 주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from konlpy.tag import Okt\n",
    "from seqeval.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data import parse, one_hot_batch, decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER based on Word Index\n",
    "\n",
    "Word index를 받은 뒤, 그 index를 one-hot vector로 만듭니다.\n",
    "\n",
    "One-hot vector는 `self.lstm`을 통해 token 주변의 context를 가지게 됩니다.[(참고)](https://pytorch.org/docs/stable/nn.html#lstm)\n",
    "lstm의 입력으로 길이가 다른 문장을 받게 되는데, 이를 고려하기 위해 `pack_padded_sequence`라는 함수를 사용합니다.\n",
    "<img src=\"https://dl.dropbox.com/s/3ze3svhdz05aakk/0705img3.gif\">\n",
    "\n",
    "`self.lstm`의 출력값을 `self.ffnn`을 통과시켜 최종 tag를 얻습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordIndexBasedNER(nn.Module):\n",
    "    def __init__(self, word_input_size, hidden_size, tag_size):\n",
    "        super(WordIndexBasedNER, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=word_input_size, hidden_size=hidden_size, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.ffnn = nn.Linear(hidden_size * 2, tag_size)\n",
    "        self.tk_len = word_input_size\n",
    "    \n",
    "    def forward(self, input_batch, word_lens, labels=None):\n",
    "        input_batch = torch.stack([torch.tensor(one_hot_batch(x, self.tk_len)) for x in input_batch]).to(device, dtype=torch.float32)\n",
    "        input_batch = nn.utils.rnn.pack_padded_sequence(input_batch, word_lens, batch_first=True, enforce_sorted=False)\n",
    "        out, _ = self.lstm(input_batch)\n",
    "        out, output_lens = nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n",
    "        out = F.dropout(out)\n",
    "        pred = self.ffnn(out)\n",
    "        \n",
    "        if labels is not None:\n",
    "            # 정답이 주어진 경우: loss를 return\n",
    "            pb = torch.zeros(torch.sum(output_lens), pred.size()[-1])\n",
    "            lb = torch.zeros(torch.sum(output_lens), dtype=torch.long)\n",
    "            lsum = 0\n",
    "            for p, la, le in zip(pred, labels, output_lens):\n",
    "                pb[lsum:lsum+le] = p[:le, :]\n",
    "                lb[lsum:lsum+le] = la[:le]\n",
    "                lsum += le\n",
    "            pred = pb\n",
    "            labels = lb\n",
    "            \n",
    "            loss = F.cross_entropy(pred, labels)\n",
    "            return loss\n",
    "        else:\n",
    "            # 정답이 주어지지 않은 경우: prediction을 return\n",
    "            pred = F.softmax(pred, dim=-1)\n",
    "            pred = torch.argmax(pred, dim=-1)\n",
    "            return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER based on Word Embedding\n",
    "\n",
    "Word index를 받은 뒤, `self.we`에서 정의된 word embedding의 row를 불러 옵니다.\n",
    "\n",
    "해당 row에는 그 단어의 word embedding이 정의되어 있습니다.\n",
    "\n",
    "Word embedding을 `self.lstm`을 통과시킵니다. 이렇게 하면 각각의 단어에 대해 contextualized embedding을 얻을 수 있습니다.\n",
    "\n",
    "마지막으로, `self.lstm`에서 얻은 token의 embedding을 feedforward network인 `self.ffnn`을 통과시켜 각각의 단어에 대한 tag를 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEmbeddingBasedNER(nn.Module):\n",
    "    def __init__(self, we, hidden_size, tag_size):\n",
    "        super(WordEmbeddingBasedNER, self).__init__()\n",
    "        self.we = nn.Embedding.from_pretrained(torch.FloatTensor(we))\n",
    "        self.lstm = nn.LSTM(input_size=self.we.embedding_dim, hidden_size=hidden_size, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.ffnn = nn.Linear(hidden_size * 2, tag_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, input_batch, word_lens, labels=None):\n",
    "#         wi, idx = word_lens.sort(0, descending=True)\n",
    "        input_batch = self.we(input_batch)\n",
    "#         input_batch = torch.index_select(input_batch, 0, idx)\n",
    "        input_batch = nn.utils.rnn.pack_padded_sequence(input_batch, word_lens, batch_first=True, enforce_sorted=False)\n",
    "        out, _ = self.lstm(input_batch)\n",
    "        out, output_lens = nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n",
    "        out = F.dropout(out)\n",
    "        pred = self.ffnn(out)\n",
    "        \n",
    "        if labels is not None:\n",
    "            pb = torch.zeros(torch.sum(output_lens), pred.size()[-1])\n",
    "            lb = torch.zeros(torch.sum(output_lens), dtype=torch.long)\n",
    "            lsum = 0\n",
    "            for p, la, le in zip(pred, labels, output_lens):\n",
    "                pb[lsum:lsum+le] = p[:le, :]\n",
    "                lb[lsum:lsum+le] = la[:le]\n",
    "                lsum += le\n",
    "            pred = pb\n",
    "            labels = lb\n",
    "#             pred = pred.view(-1, pred.size()[-1])\n",
    "            \n",
    "            loss = F.cross_entropy(pred, labels)\n",
    "            return loss\n",
    "        else:\n",
    "            pred = F.softmax(pred, dim=-1)\n",
    "            pred = torch.argmax(pred, dim=-1)\n",
    "            return pred\n",
    "#         return pred, output_lens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset generation\n",
    "[torch data module](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html)을 사용하여 data를 loading하는 구조체를 만듭니다.\n",
    "\n",
    "Dataset은 data를 저장하고 index-based로 data의 tensor화된 자료를 얻어오게 됩니다. 따라서 데이터를 tensor로 변환하는 과정이 필요합니다.\n",
    "\n",
    "Data는 word와 tag로 이루어져 있는데, 이 task에서의 dataset은 각각의 data에 대해 *word index*, *tag index*, *token length*를 return합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, token_index_dict, tag_index_dict):\n",
    "        self.data = data\n",
    "        self.token2i = token_index_dict\n",
    "        self.tag2i = tag_index_dict\n",
    "        self.maxlen = max(map(len, data))\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index]\n",
    "        return torch.tensor([self.token2i[x] if x in self.token2i else 0 for x, _ in data] + ([0] * (self.maxlen - len(data)))), \\\n",
    "                torch.tensor([self.tag2i[x] for _, x in data] + ([0] * (self.maxlen - len(data)))), \\\n",
    "                len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load corpus and embedding\n",
    "학습, 테스트용 corpus와 모델에 사용할 Word embedding 파일을 불러옵니다.\n",
    "\n",
    "Word embedding의 경우, 학습되지 않은 단어에 대한 임베딩은 0벡터를 부여합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parsed_data = parse(\"corpus/parsed.txt\")\n",
    "train_data = parsed_data[:-1000]\n",
    "dev_data = parsed_data[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_ids = {\"_UNK_\": 0} # 0번 id에 더미 입력\n",
    "with open(\"wiki_tok_glove_300.word\", encoding=\"UTF8\") as f:\n",
    "    for line in f.readlines():\n",
    "        tok_ids[line.strip()] = len(tok_ids)\n",
    "we = np.load(\"wiki_tok_glove_300.npy\")\n",
    "we = np.vstack([np.zeros([1, we.shape[1]]), we] # 0번 row에 0벡터 입력\n",
    "               \n",
    "print(tok_ids[\"하이닉스\"], we[tok_ids[\"하이닉스\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make token/tag dictionary\n",
    "token_dict = set([])\n",
    "tag_dict = set([])\n",
    "for sent in train_data+dev_data:\n",
    "    for token, tag in sent:\n",
    "        token_dict.add(token)\n",
    "        tag_dict.add(tag)\n",
    "\n",
    "token_dict = {t: i for i, t in enumerate(token_dict)}\n",
    "tag_dict = {t: i for i, t in enumerate(tag_dict)}\n",
    "\n",
    "i2tag = {i: t for t, i in tag_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504227 26256 11\n",
      "{'I-DT': 0, 'B-PS': 1, 'I-OG': 2, 'B-DT': 3, 'I-PS': 4, 'I-TI': 5, 'B-TI': 6, 'B-LC': 7, 'I-LC': 8, 'O': 9, 'B-OG': 10}\n",
      "{0: 'I-DT', 1: 'B-PS', 2: 'I-OG', 3: 'B-DT', 4: 'I-PS', 5: 'I-TI', 6: 'B-TI', 7: 'B-LC', 8: 'I-LC', 9: 'O', 10: 'B-OG'}\n"
     ]
    }
   ],
   "source": [
    "print(len(tok_ids), len(token_dict), len(tag_dict))\n",
    "print(tag_dict)\n",
    "print(i2tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('\\ufeff', 'O'), ('특히', 'O'), ('김병현', 'B-PS'), ('은', 'O'), ('4회', 'O'), ('말에', 'O'), ('무기', 'O'), ('력', 'O'), ('하게', 'O'), ('6', 'O'), ('실점', 'O'), ('하면서', 'O')]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module과 optimizer를 정의합니다. Word index 기반 모듈을 `ner_wi_module`, embedding 기반 모듈을 `ner_we_module`로 정의합니다. `self.lstm`의 hidden layer size는 256으로 설정했습니다.\n",
    "\n",
    "Optimizer의 경우, Adam optimizer를 사용합니다. optimizer에는 각각의 모듈의 parameter가 학습 대상임을 알려주고, learning rate를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize module\n",
    "ner_wi_module = WordIndexBasedNER(len(token_dict), 256, len(tag_dict)).to(device)\n",
    "ner_we_module = WordEmbeddingBasedNER(we, 256, len(tag_dict)).to(device)\n",
    "# ner_parallel = torch.DataParallel(ner_module)\n",
    "wi_optimizer = torch.optim.Adam(ner_wi_module.parameters(), lr=0.0001)\n",
    "we_optimizer = torch.optim.Adam(ner_we_module.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Word index based module\n",
    "Train 과정은 다음과 같이 이루어집니다.\n",
    "1. Batch load\n",
    "2. Prediction\n",
    "3. 정답과 비교 후 loss 계산\n",
    "4. Backpropagation\n",
    "5. Evaluation score 계산\n",
    "\n",
    "Data loading은 [Cell 5](#Dataset-generation) 에서 정의한 dataset 모듈을 바탕으로 한 DataLoader 모듈을 사용하여 이루어집니다. DataLoader는 Dataset에서 정의된 output tensor들을 여러 변환을 통해 가져올 수 있는 모듈입니다.\n",
    "\n",
    "module은 train mode와 eval mode가 있습니다. train시에는 dropout과 같은 train과정에만 적용되어야 하는 것들이 적용되고, eval시에는 해당 부분들이 동작하지 않습니다.\n",
    "\n",
    "loss backpropagation은 prediction을 구한 뒤, label과 비교하여 loss를 얻고, `loss.backward()`, `optimizer.step()`을 통해 backpropagation을 수행합니다.(해당 코드는 모듈 내 구현되어 있습니다. 모듈의 `forward()`함수에서 `if labels is not None:` 부분이 label과 비교하여 loss를 구하는 부분입니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# train iteration\n",
    "max_epoch = 0\n",
    "eval_per_epoch = 2\n",
    "\n",
    "train_dataset = NERDataset(train_data, token_dict, tag_dict)\n",
    "dev_dataset = NERDataset(dev_data, token_dict, tag_dict)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=32)\n",
    "dev_dataloader = DataLoader(dev_dataset, shuffle=False, batch_size=32)\n",
    "\n",
    "best_f1 = 0\n",
    "best_epoch = 0\n",
    "nbc = 0\n",
    "tq = tqdm(range(1, max_epoch+1))\n",
    "for epoch in tq:\n",
    "    ner_wi_module.train()\n",
    "    total_loss = 0\n",
    "    for token_batch, tag_batch, data_len in train_dataloader: #1\n",
    "        wi_optimizer.zero_grad()\n",
    "        token_batch, tag_batch, data_len = token_batch.to(device), tag_batch.to(device), data_len.to(device)\n",
    "        max_data_len = torch.max(data_len)\n",
    "        loss = ner_wi_module(token_batch, data_len, tag_batch) #2, #3\n",
    "        total_loss += loss\n",
    "        loss.backward() #4\n",
    "        wi_optimizer.step() #4\n",
    "    tq.desc = \"Epoch %d Loss %f\" % (epoch, total_loss)\n",
    "    if epoch % eval_per_epoch == 0: #Evaluation mode\n",
    "        ner_wi_module.eval()\n",
    "        preds = []\n",
    "        golds = []\n",
    "        lens_with_pad = []\n",
    "        data_lens = []\n",
    "        for token_batch, tag_batch, data_len in dev_dataloader:\n",
    "            \n",
    "            token_batch, data_len = token_batch.to(device), data_len.to(device)\n",
    "            pred = ner_wi_module(token_batch, data_len)\n",
    "            for p, t, d in zip(pred, tag_batch, data_len):\n",
    "                preds.append([i2tag[x.item()] for x in p[:d]])\n",
    "                golds.append([i2tag[x.item()] for x in t[:d]])\n",
    "                data_lens.append(d)\n",
    "        f1 = f1_score(golds, preds) #5\n",
    "        nbc += eval_per_epoch\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_epoch = epoch\n",
    "            torch.save(ner_wi_module.state_dict(), \"wi_model\")\n",
    "            nbc = 0\n",
    "        \n",
    "        idx = 0\n",
    "        with open(\"debug/wi_eval_%d.tsv\" % epoch, \"w\", encoding=\"UTF8\") as f:\n",
    "            for b in dev_data:\n",
    "                \n",
    "                for i, (token, tag) in enumerate(b):\n",
    "                    assert golds[idx][i] == tag\n",
    "                    f.write(\"\\t\".join([token, tag, preds[idx][i]])+\"\\n\")\n",
    "                f.write(\"\\n\")\n",
    "                idx += 1\n",
    "        print(\"Epoch %d F1 score %.2f\" % (epoch, f1 * 100))\n",
    "        print(\"Best F1 %.2f at Epoch %d\" % (best_f1 * 100, best_epoch))\n",
    "        if nbc >= 30:\n",
    "            print(\"No better result since epoch %d - stop training\" % best_epoch)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train word embedding based module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss 99.065842:   0%|          | 5/1000 [00:50<2:57:35, 10.71s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 F1 score 34.50\n",
      "Best F1 34.50 at Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Loss 77.676620:   1%|          | 10/1000 [01:41<3:00:20, 10.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 F1 score 40.92\n",
      "Best F1 40.92 at Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 Loss 65.804337:   2%|▏         | 15/1000 [02:32<3:01:17, 11.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 F1 score 42.57\n",
      "Best F1 42.57 at Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 Loss 56.054779:   2%|▏         | 20/1000 [03:23<3:01:18, 11.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 F1 score 44.37\n",
      "Best F1 44.37 at Epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 Loss 47.575470:   2%|▎         | 25/1000 [04:14<3:01:29, 11.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 F1 score 45.28\n",
      "Best F1 45.28 at Epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 Loss 40.151180:   3%|▎         | 30/1000 [05:05<2:58:04, 11.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 F1 score 45.32\n",
      "Best F1 45.32 at Epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35 Loss 33.292904:   4%|▎         | 35/1000 [05:52<2:38:47,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 F1 score 44.32\n",
      "Best F1 45.32 at Epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40 Loss 27.347027:   4%|▍         | 40/1000 [06:39<2:33:47,  9.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 F1 score 45.05\n",
      "Best F1 45.32 at Epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45 Loss 22.365026:   4%|▍         | 45/1000 [07:26<2:32:09,  9.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 F1 score 44.29\n",
      "Best F1 45.32 at Epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50 Loss 18.518879:   5%|▌         | 50/1000 [08:13<2:32:45,  9.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 F1 score 45.22\n",
      "Best F1 45.32 at Epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55 Loss 15.337384:   6%|▌         | 55/1000 [08:59<2:31:14,  9.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 F1 score 44.91\n",
      "Best F1 45.32 at Epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59 Loss 13.038646:   6%|▌         | 59/1000 [09:36<2:24:43,  9.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 F1 score 44.17\n",
      "Best F1 45.32 at Epoch 30\n",
      "No better result since epoch 30 - stop training\n"
     ]
    }
   ],
   "source": [
    "from evaluation import eval_ner\n",
    "# train iteration\n",
    "max_epoch = 1000\n",
    "eval_per_epoch = 5\n",
    "\n",
    "train_dataset = NERDataset(train_data, tok_ids, tag_dict)\n",
    "dev_dataset = NERDataset(dev_data, tok_ids, tag_dict)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=32)\n",
    "dev_dataloader = DataLoader(dev_dataset, shuffle=False, batch_size=32)\n",
    "\n",
    "best_f1 = 0\n",
    "best_epoch = 0\n",
    "nbc = 0\n",
    "# ner_parallel = nn.DataParallel(ner_module)\n",
    "tq = tqdm(range(1, max_epoch+1))\n",
    "for epoch in tq:\n",
    "    ner_we_module.train()\n",
    "    total_loss = 0\n",
    "    for token_batch, tag_batch, data_len in train_dataloader:\n",
    "        we_optimizer.zero_grad()\n",
    "        token_batch, tag_batch, data_len = token_batch.to(device), tag_batch.to(device), data_len.to(device)\n",
    "        max_data_len = torch.max(data_len)\n",
    "        loss = ner_we_module(token_batch, data_len, tag_batch)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        we_optimizer.step()\n",
    "    tq.desc = \"Epoch %d Loss %f\" % (epoch, total_loss)\n",
    "    if epoch % eval_per_epoch == 0:\n",
    "        ner_we_module.eval()\n",
    "        preds = []\n",
    "        golds = []\n",
    "        lens_with_pad = []\n",
    "        data_lens = []\n",
    "        for token_batch, tag_batch, data_len in dev_dataloader:\n",
    "            \n",
    "            token_batch, data_len = token_batch.to(device), data_len.to(device)\n",
    "            pred = ner_we_module(token_batch, data_len)\n",
    "            for p, t, d in zip(pred, tag_batch, data_len):\n",
    "                preds.append([i2tag[x.item()] for x in p[:d]])\n",
    "                golds.append([i2tag[x.item()] for x in t[:d]])\n",
    "                data_lens.append(d)\n",
    "        f1 = f1_score(golds, preds)\n",
    "        nbc += eval_per_epoch\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_epoch = epoch\n",
    "            torch.save(ner_we_module.state_dict(), \"we_model\")\n",
    "            nbc = 0\n",
    "        \n",
    "        idx = 0\n",
    "        with open(\"debug/we_eval_%d.tsv\" % epoch, \"w\", encoding=\"UTF8\") as f:\n",
    "            for b in dev_data:\n",
    "                \n",
    "                for i, (token, tag) in enumerate(b):\n",
    "                    assert golds[idx][i] == tag\n",
    "                    f.write(\"\\t\".join([token, tag, preds[idx][i]])+\"\\n\")\n",
    "                f.write(\"\\n\")\n",
    "                idx += 1\n",
    "        print(\"Epoch %d F1 score %.2f\" % (epoch, f1 * 100))\n",
    "        print(\"Best F1 %.2f at Epoch %d\" % (best_f1 * 100, best_epoch))\n",
    "        if nbc >= 30:\n",
    "            print(\"No better result since epoch %d - stop training\" % best_epoch)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application\n",
    "실제 학습된 모델을 적용해봅니다. 원문 sentence가 들어왔을 때, sentence를 형태소 분석을 하여 단어의 의미를 더 잘 표현하게 해 주고, 이를 model에 넣어서 tag 예측을 한 뒤 BIO 태그를 decode합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<7월:PS> 10일 <SK 와이번스:OG> 는 <한화 이글스:OG> 를 상대로 승리 하였다 .\n"
     ]
    }
   ],
   "source": [
    "okt = Okt()\n",
    "def sentence_ner(sentence):\n",
    "    morphs = okt.morphs(sentence)\n",
    "    word_indexes = torch.LongTensor([tok_ids[morph] if morph in tok_ids else 0 for morph in morphs]).to(device).unsqueeze(0)\n",
    "    word_len = torch.LongTensor([len(morphs)])\n",
    "    pred = ner_we_module(word_indexes, word_len)\n",
    "    pred = [i2tag[x.item()] for x in pred[0]]\n",
    "    print(decode(morphs, pred))\n",
    "\n",
    "sentence_ner(\"7월 10일 SK 와이번스는 한화 이글스를 상대로 승리하였다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
